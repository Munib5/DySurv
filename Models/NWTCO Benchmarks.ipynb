{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import xarray\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper \n",
    "from pycox.models import DeepHitSingle\n",
    "\n",
    "import torch # For building the networks \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchtuples as tt # Some useful functions\n",
    "\n",
    "from pycox.datasets import nwtco\n",
    "from pycox.models import LogisticHazard\n",
    "from pycox.models import CoxPH\n",
    "from pycox.models.loss import NLLLogistiHazardLoss, NLLMTLRLoss, BCESurvLoss\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set_theme(style=\"white\", palette=\"rocket_r\")\n",
    "\n",
    "np.random.seed(1234)\n",
    "_ = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = nwtco.read_df()\n",
    "df_test = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_standardize = ['age']\n",
    "cols_leave = ['stage', 'in.subcohort', 'instit_2', 'histol_2', 'study_4']\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize + leave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f253673d",
   "metadata": {},
   "source": [
    "# PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "labtrans = PMF.label_transform(num_durations)\n",
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb03f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.5\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PMF(net, tt.optim.Adam, duration_index=labtrans.cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c099b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lr_finder = model.lr_finder(x_train, y_train, batch_size, tolerance=4)\n",
    "_ = lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(lr_finder.get_best_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ad796",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.interpolate(10).predict_surv_df(x_test)\n",
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677495fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db655f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3355d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ffb52e",
   "metadata": {},
   "source": [
    "# MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009af96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "labtrans = MTLR.label_transform(num_durations)\n",
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c78ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MTLR(net, tt.optim.Adam, duration_index=labtrans.cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr_finder = model.lr_finder(x_train, y_train, batch_size, tolerance=6)\n",
    "_ = lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d342222",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(lr_finder.get_best_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ac8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac1d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e390035",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61754138",
   "metadata": {},
   "source": [
    "# BCESurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a611ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import LogisticHazard, BCESurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labtrans = LogisticHazard.label_transform(10)\n",
    "get_dur_ev = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "\n",
    "y_train = labtrans.fit_transform(*get_dur_ev(df_train))\n",
    "y_val = labtrans.transform(*get_dur_ev(df_val))\n",
    "y_test = labtrans.transform(*get_dur_ev(df_test))\n",
    "\n",
    "train = tt.tuplefy(x_train, y_train)\n",
    "val = tt.tuplefy(x_val, y_val)\n",
    "test = tt.tuplefy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138291f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.4\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "n_itp=20\n",
    "\n",
    "model = BCESurv(net, tt.optim.AdamWR(lr, cycle_eta_multiplier=0.8), duration_index=labtrans.cuts)\n",
    "log = model.fit(*train, 256, 256, verbose=False, val_data=val,\n",
    "                    callbacks=[tt.cb.EarlyStoppingCycle()])\n",
    "surv = model.interpolate(n_itp).predict_surv_df(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.log.to_pandas().iloc[1:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_bce_true = EvalSurv(surv, durations_test, events_test, 'km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff01632",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid = np.linspace(0, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510eb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d89e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aece417",
   "metadata": {},
   "source": [
    "# DeepHit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a146b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import DeepHitSingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a65e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32,32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.4\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d58534",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr_finder = model.lr_finder(x_train, y_train, batch_size, tolerance=3)\n",
    "_ = lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(lr_finder.get_best_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ab75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbba9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45523284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089316ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2e0b9",
   "metadata": {},
   "source": [
    "# CoxTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import CoxTime\n",
    "from pycox.models.cox_time import MLPVanillaCoxTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2650850",
   "metadata": {},
   "outputs": [],
   "source": [
    "labtrans = CoxTime.label_transform()\n",
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "durations_test, events_test = get_target(df_test)\n",
    "val = tt.tuplefy(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "net = MLPVanillaCoxTime(in_features, num_nodes, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoxTime(net, tt.optim.Adam, labtrans=labtrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lrfinder = model.lr_finder(x_train, y_train, batch_size, tolerance=2)\n",
    "_ = lrfinder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfinder.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(lrfinder.get_best_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = model.fit(x_train, y_train, batch_size, epochs, verbose,\n",
    "                val_data=val.repeat(10).cat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ce1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04386c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.compute_baseline_hazards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5551f2c",
   "metadata": {},
   "source": [
    "# Cox-CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d23c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import CoxCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f305d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = get_target(df_train)\n",
    "y_val = get_target(df_val)\n",
    "durations_test, events_test = get_target(df_test)\n",
    "val = tt.tuplefy(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "output_bias = False\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
    "                              dropout, output_bias=output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoxCC(net, tt.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ada954",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lrfinder = model.lr_finder(x_train, y_train, batch_size, tolerance=2)\n",
    "_ = lrfinder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfinder.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(lrfinder.get_best_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46bcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8347e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = model.fit(x_train, y_train, batch_size, epochs, verbose,\n",
    "                val_data=val.repeat(10).cat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0873f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfed652",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.compute_baseline_hazards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626172a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e41a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ccd9c",
   "metadata": {},
   "source": [
    "# DeepSurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import CoxPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = get_target(df_train)\n",
    "y_val = get_target(df_val)\n",
    "durations_test, events_test = get_target(df_test)\n",
    "val = x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03daa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32, 32, 32, 32]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.0\n",
    "output_bias = False\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
    "                              dropout, output_bias=output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoxPH(net, tt.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lrfinder = model.lr_finder(x_train, y_train, batch_size, tolerance=10)\n",
    "_ = lrfinder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfinder.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35552ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(lrfinder.get_best_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = model.fit(x_train, y_train, batch_size, epochs, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86061a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691558c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.compute_baseline_hazards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8217246",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689be82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1b0ff",
   "metadata": {},
   "source": [
    "# PCHazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import PCHazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7da57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "labtrans = PCHazard.label_transform(num_durations)\n",
    "get_target = lambda df: (df['edrel'].values.astype(float), df['rel'].values.astype(float))\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcee137",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCHazard(net, tt.optim.Adam, duration_index=labtrans.cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lr_finder = model.lr_finder(x_train, y_train, batch_size, tolerance=8)\n",
    "_ = lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810756c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(lr_finder.get_best_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97529f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d40ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77572596",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dfb3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e6ffe",
   "metadata": {},
   "source": [
    "# Logistic Hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import LogisticHazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912007e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "\n",
    "labtrans = LogisticHazard.label_transform(num_durations)\n",
    "# labtrans = PMF.label_transform(num_durations)\n",
    "# labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "\n",
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65001bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticHazard(net, tt.optim.Adam(0.001), duration_index=labtrans.cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4885169",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = model.fit(x_train, y_train, batch_size, epochs, val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a077037",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f097e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e68afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1861f",
   "metadata": {},
   "source": [
    "# DySurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "\n",
    "labtrans = LogisticHazard.label_transform(num_durations)\n",
    "# labtrans = PMF.label_transform(num_durations)\n",
    "# labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "\n",
    "get_target = lambda df: (df['edrel'].values, df['rel'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = tt.tuplefy(x_train, (y_train, x_train))\n",
    "val = tt.tuplefy(x_val, (y_val, x_val))\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ba07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, no_features, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.no_features = no_features\n",
    "        self.hidden_size = no_features\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.hidden_size, 3*self.hidden_size)\n",
    "        self.fc2 = nn.Linear(3*self.hidden_size, 5*self.hidden_size)\n",
    "        self.fc3 = nn.Linear(5*self.hidden_size, 3*self.hidden_size)\n",
    "        self.fc4 = nn.Linear(3*self.hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        out = self.fc4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DySurv(nn.Module):\n",
    "    def __init__(self, in_features, encoded_features, out_features):\n",
    "        super().__init__()\n",
    "        self.fc11 = nn.Linear(in_features, 3*in_features)\n",
    "        self.fc12 = nn.Linear(3*in_features, 5*in_features)\n",
    "        self.fc13 = nn.Linear(5*in_features, 3*in_features)\n",
    "        self.fc14 = nn.Linear(3*in_features, encoded_features)\n",
    "\n",
    "        self.fc24 = nn.Linear(3*in_features, encoded_features)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.surv_net = nn.Sequential(\n",
    "            nn.Linear(encoded_features, 3*in_features), nn.ReLU(),\n",
    "            nn.Linear(3*in_features, 5*in_features), nn.ReLU(),\n",
    "            nn.Linear(5*in_features, 3*in_features), nn.ReLU(),\n",
    "            nn.Linear(3*in_features, out_features),\n",
    "        )\n",
    "        \n",
    "        self.decoder2 = Decoder(encoded_features, in_features)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = std.data.new(std.size()).normal_()\n",
    "        sample_z = eps.mul(std).add_(mu)\n",
    "\n",
    "        return sample_z\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        x = self.relu(self.fc11(x)\n",
    "        x = self.relu(self.fc12(x))\n",
    "        x = self.relu(self.fc13(x))\n",
    "        mu_z = self.fc14(x)\n",
    "        logvar_z = self.fc24(x)\n",
    "\n",
    "        return mu_z, logvar_z\n",
    "\n",
    "    def forward(self, input):\n",
    "                      \n",
    "        mu, logvar = self.encoder(input.float())\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder2(z), self.surv_net(z), mu, logvar\n",
    "\n",
    "    def predict(self, input):\n",
    "        # Will be used by model.predict later.\n",
    "        # As this only has the survival output, \n",
    "        # we don't have to change LogisticHazard.\n",
    "        mu, logvar = self.encoder(input)\n",
    "        encoded = self.reparameterize(mu, logvar)\n",
    "        return self.surv_net(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "encoded_features = 20\n",
    "out_features = labtrans.out_features\n",
    "net = DySurv(in_features, encoded_features, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Loss(torch.nn.Module):\n",
    "    def __init__(self, reduction: str = 'mean') -> None:\n",
    "        super().__init__()\n",
    "        self.reduction = reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ba60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_logistic_hazard(phi: Tensor, idx_durations: Tensor, events: Tensor,\n",
    "                        reduction: str = 'mean') -> Tensor:\n",
    "    \"\"\"\n",
    "    References:\n",
    "    [1] Håvard Kvamme and Ørnulf Borgan. Continuous and Discrete-Time Survival Prediction\n",
    "        with Neural Networks. arXiv preprint arXiv:1910.06724, 2019.\n",
    "        https://arxiv.org/pdf/1910.06724.pdf\n",
    "    \"\"\"\n",
    "    if phi.shape[1] <= idx_durations.max():\n",
    "        raise ValueError(f\"Network output `phi` is too small for `idx_durations`.\"+\n",
    "                         f\" Need at least `phi.shape[1] = {idx_durations.max().item()+1}`,\"+\n",
    "                         f\" but got `phi.shape[1] = {phi.shape[1]}`\")\n",
    "    if events.dtype is torch.bool:\n",
    "        events = events.float()\n",
    "    events = events.view(-1, 1)\n",
    "    idx_durations = idx_durations.view(-1, 1)\n",
    "    y_bce = torch.zeros_like(phi).scatter(1, idx_durations, events)\n",
    "    bce = F.binary_cross_entropy_with_logits(phi, y_bce, reduction='none')\n",
    "    loss = bce.cumsum(1).gather(1, idx_durations).view(-1)\n",
    "    return _reduction(loss, reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLLogistiHazardLoss(_Loss):\n",
    "    def forward(self, phi: Tensor, idx_durations: Tensor, events: Tensor) -> Tensor:\n",
    "        return nll_logistic_hazard(phi, idx_durations, events, self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, alpha):\n",
    "        super().__init__()\n",
    "        assert (alpha >= 0) and (alpha <= 1), 'Need `alpha` in [0, 1].'\n",
    "        self.alpha = alpha\n",
    "        self.loss_surv = NLLLogistiHazardLoss()\n",
    "        self.loss_ae = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, decoded, phi, mu, logvar, target_loghaz, target_ae):\n",
    "        idx_durations, events = target_loghaz\n",
    "        loss_surv = self.loss_surv(phi, idx_durations, events)/10\n",
    "        loss_ae = self.loss_ae(decoded, target_ae)/1\n",
    "        loss_kd = (-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))/10\n",
    "        return self.alpha[0] * loss_surv + self.alpha[1] * loss_ae + self.alpha[2] * loss_kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da533e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticHazard(net, tt.optim.Adam(0.001), duration_index=labtrans.cuts, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f755f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = dict(\n",
    "    loss_surv = LossAELogHaz(1),\n",
    "    loss_ae   = LossAELogHaz(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 1000\n",
    "log = model.fit(*train, batch_size, epochs, False, val_data=val, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.log.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d06b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = res[['train_loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.interpolate(10).predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ed728",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv.iloc[:, 0:5].plot(drawstyle='steps-post')\n",
    "plt.ylabel('S(t | x)')\n",
    "_ = plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td('adj_antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921efd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4763ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e84c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.integrated_nbll(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc95c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
